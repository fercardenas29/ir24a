{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333ae546d607a744",
   "metadata": {},
   "source": [
    "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
    "\n",
    "## Objective:\n",
    "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88bf1f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e729fcfa",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "Import necessary libraries for data handling, text processing, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb4e65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\usuario\\Fer-Pc\\Escritorio\\EPN\\2024-A\\SEPTIMO_SEMESTRE\\RECUPERACION_DE_INFORMACION\\ir24a\\venv3.8\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#delete stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stop_words.update(punctuations)\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711da120",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset\n",
    "\n",
    "Load the dataset of podcast transcripts.\n",
    "\n",
    "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5408bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id            guest                    title  \\\n",
      "0   1      Max Tegmark                 Life 3.0   \n",
      "1   2    Christof Koch            Consciousness   \n",
      "2   3    Steven Pinker  AI in the Age of Reason   \n",
      "3   4    Yoshua Bengio            Deep Learning   \n",
      "4   5  Vladimir Vapnik     Statistical Learning   \n",
      "\n",
      "                                                text  \n",
      "0  As part of MIT course 6S099, Artificial Genera...  \n",
      "1  As part of MIT course 6S099 on artificial gene...  \n",
      "2  You've studied the human mind, cognition, lang...  \n",
      "3  What difference between biological neural netw...  \n",
      "4  The following is a conversation with Vladimir ...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/podcastdata_dataset.csv')\n",
    "print(df.head())\n",
    "corpus = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f8e10",
   "metadata": {},
   "source": [
    "### Step 3: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87849c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convertir el texto a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar signos de puntuación\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Eliminar stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d10b7e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  As part of MIT course 6S099, Artificial Genera...   \n",
      "1  As part of MIT course 6S099 on artificial gene...   \n",
      "2  You've studied the human mind, cognition, lang...   \n",
      "3  What difference between biological neural netw...   \n",
      "4  The following is a conversation with Vladimir ...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  part mit course 6s099 artificial general intel...  \n",
      "1  part mit course 6s099 artificial general intel...  \n",
      "2  youve studied human mind cognition language vi...  \n",
      "3  difference biological neural networks artifici...  \n",
      "4  following conversation vladimir vapnik hes co ...  \n"
     ]
    }
   ],
   "source": [
    "# Aplica la función clean_text a la columna 'text' y guarda el resultado en una nueva columna 'cleaned_text'\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "print(df[['text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0939846d",
   "metadata": {},
   "source": [
    "###  Step 4: Vector Space Representation - TF-IDF\n",
    "\n",
    "Create TF-IDF vector representations of the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2c621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d4ffa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 49728)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5e2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte la matriz TF-IDF a un DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_vectors.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76eb505",
   "metadata": {},
   "source": [
    "### Step 5: Vector Space Representation - BERT\n",
    "\n",
    "Create BERT vector representations of the transcripts using a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea420eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e39d289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para obtener las representaciones de BERT\n",
    "def generate_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "        outputs = bert_model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :].detach().numpy())  # Use [CLS] token representation\n",
    "    return np.array(embeddings).transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a6d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera las representaciones de BERT para el corpus de textos limpios\n",
    "cleaned_corpus = df['cleaned_text'].tolist()\n",
    "corpus_bert_embeddings = generate_bert_embeddings(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc2aab8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 768, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bert_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sims_bert                                                 ep\n",
      "0     0.561838                                           Life 3.0\n",
      "1     0.590867                                      Consciousness\n",
      "2     0.591847                            AI in the Age of Reason\n",
      "3     0.605100                                      Deep Learning\n",
      "4     0.571484                               Statistical Learning\n",
      "..         ...                                                ...\n",
      "314   0.594952    Singularity, Superintelligence, and Immortality\n",
      "315   0.539820   Emotion AI, Social Robots, and Self-Driving Cars\n",
      "316   0.569350  Comedy, MADtv, AI, Friendship, Madness, and Pr...\n",
      "317   0.518504                                              Poker\n",
      "318   0.540916  Biology, Life, Aliens, Evolution, Embryogenesi...\n",
      "\n",
      "[319 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"GPT 3.0\"\n",
    "result_bert = retrieve_bert(query)\n",
    "print(result_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225b220",
   "metadata": {},
   "source": [
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dad010a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la función de recuperación usando TF-IDF\n",
    "def retrieve_tfidf(query):\n",
    "    # Asegúrate de que la consulta sea una cadena de texto\n",
    "    if isinstance(query, list):\n",
    "        query = ' '.join(query)\n",
    "    \n",
    "    query = clean_text(query)\n",
    "    query_vector = tfidf_vectorizer.transform([query])\n",
    "    similitudes = cosine_similarity(tfidf_vectors, query_vector)\n",
    "    similitudes_df = pd.DataFrame(similitudes, columns=['sims_tfidf'])\n",
    "    similitudes_df['ep'] = df['title']\n",
    "    return similitudes_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "423707ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sims_tfidf                                                 ep\n",
      "0      0.002110                                           Life 3.0\n",
      "1      0.002588                                      Consciousness\n",
      "2      0.000000                            AI in the Age of Reason\n",
      "3      0.000000                                      Deep Learning\n",
      "4      0.000000                               Statistical Learning\n",
      "..          ...                                                ...\n",
      "314    0.001021    Singularity, Superintelligence, and Immortality\n",
      "315    0.003847   Emotion AI, Social Robots, and Self-Driving Cars\n",
      "316    0.000000  Comedy, MADtv, AI, Friendship, Madness, and Pr...\n",
      "317    0.002649                                              Poker\n",
      "318    0.000000  Biology, Life, Aliens, Evolution, Embryogenesi...\n",
      "\n",
      "[319 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"GPT 3.0\"\n",
    "result_tfidf = retrieve_tfidf(query)\n",
    "print(result_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5732e3",
   "metadata": {},
   "source": [
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "151bbfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define la función de recuperación usando TF-IDF\n",
    "def retrieve_bert(query):  \n",
    "    query = clean_text(query)\n",
    "    query_bert = generate_bert_embeddings([query])\n",
    "    query_bert = query_bert.reshape(1, -1)  # Asegúrate de que el vector de consulta tenga la forma correcta\n",
    "    corpus_bert_embeddings_reshaped = corpus_bert_embeddings.reshape(len(df), -1)  # Asegúrate de que el corpus tenga la forma correcta\n",
    "    similitudes = cosine_similarity(corpus_bert_embeddings_reshaped, query_bert)\n",
    "    similitudes_df = pd.DataFrame(similitudes, columns=['sims_bert'])\n",
    "    similitudes_df['ep'] = df['title']\n",
    "    return similitudes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e24feb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sims_bert                                                 ep\n",
      "0     0.561838                                           Life 3.0\n",
      "1     0.590867                                      Consciousness\n",
      "2     0.591847                            AI in the Age of Reason\n",
      "3     0.605100                                      Deep Learning\n",
      "4     0.571484                               Statistical Learning\n",
      "..         ...                                                ...\n",
      "314   0.594952    Singularity, Superintelligence, and Immortality\n",
      "315   0.539820   Emotion AI, Social Robots, and Self-Driving Cars\n",
      "316   0.569350  Comedy, MADtv, AI, Friendship, Madness, and Pr...\n",
      "317   0.518504                                              Poker\n",
      "318   0.540916  Biology, Life, Aliens, Evolution, Embryogenesi...\n",
      "\n",
      "[319 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"GPT 3.0\"\n",
    "result_bert = retrieve_bert(query)\n",
    "print(result_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d660f7f3",
   "metadata": {},
   "source": [
    "### Step 7: Retrieve and Compare Results\n",
    "\n",
    "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77673caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener los 10 mejores resultados de TF-IDF\n",
    "top_tfidf = result_tfidf.sort_values(by='sims_tfidf', ascending=False).head(top_n)\n",
    "\n",
    "# Obtener los 10 mejores resultados de BERT\n",
    "top_bert = result_bert.sort_values(by='sims_bert', ascending=False).head(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9642cd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 resultados TF-IDF:\n",
      "     sims_tfidf                                                 ep\n",
      "213    0.094562  OpenAI Codex, GPT-3, Robotics, and the Future ...\n",
      "17     0.031548                                     OpenAI and AGI\n",
      "120    0.028172                    Friendship with an AI Companion\n",
      "94     0.027958                                      Deep Learning\n",
      "117    0.024249  Math, Manim, Neural Networks & Teaching with 3...\n",
      "119    0.013067                           Measures of Intelligence\n",
      "130    0.011653  The Future of Computing and Programming Languages\n",
      "7      0.010065                                             Google\n",
      "89     0.009755        Cellular Automata, Computation, and Physics\n",
      "140    0.009667   Economics of AI, Social Networks, and Technology\n",
      "\n",
      "Top 10 resultados BERT:\n",
      "     sims_bert                                                 ep\n",
      "68    0.653917                                  YouTube Algorithm\n",
      "296   0.640073                 Marxism, Capitalism, and Economics\n",
      "168   0.633540         Solving Martial Arts from First Principles\n",
      "185   0.626535                   Kernel Brain-Computer Interfaces\n",
      "105   0.624222       Neuroscience, Psychology, and AI at DeepMind\n",
      "11    0.623840                              Poker and Game Theory\n",
      "261   0.622282                                         Big Pharma\n",
      "165   0.622211  Deep Work, Focus, Productivity, Email, and Soc...\n",
      "39    0.622120                                             iRobot\n",
      "99    0.622115         Neuroscience and the Free Energy Principle\n"
     ]
    }
   ],
   "source": [
    "# Imprimir los resultados en DataFrames separados\n",
    "print(\"Top 10 resultados TF-IDF:\")\n",
    "print(top_tfidf)\n",
    "\n",
    "print(\"\\nTop 10 resultados BERT:\")\n",
    "print(top_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a934919d95ac2de",
   "metadata": {},
   "source": [
    "### Step 8: Test the IR System\n",
    "\n",
    "Test the system with a sample query.\n",
    "\n",
    "Retrieve and display the top results using both TF-IDF and BERT representations.\n",
    "\n",
    "### Step 9: Compare Results\n",
    "\n",
    "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
    "\n",
    "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "* Follow the steps outlined above to implement the IR system.\n",
    "* Run the provided code snippets to understand how each part of the system works.\n",
    "* Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
    "* Compare and analyze the results. Discuss the pros and cons of each method.\n",
    "* Document your findings and any improvements you make to the system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
