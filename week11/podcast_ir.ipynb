{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333ae546d607a744",
   "metadata": {},
   "source": [
    "# Workshop: Building an Information Retrieval System for Podcast Episodes\n",
    "\n",
    "## Objective:\n",
    "Create an Information Retrieval (IR) system that processes a dataset of podcast transcripts and, given a query, returns the episodes where the host and guest discuss the query topic. Use TF-IDF and BERT for vector space representation and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88bf1f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e729fcfa",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "Import necessary libraries for data handling, text processing, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aeb4e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#delete stopwords\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stop_words.update(punctuations)\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711da120",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset\n",
    "\n",
    "Load the dataset of podcast transcripts.\n",
    "\n",
    "Find the dataset in: https://www.kaggle.com/datasets/rajneesh231/lex-fridman-podcast-transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf5408bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id            guest                    title  \\\n",
      "0   1      Max Tegmark                 Life 3.0   \n",
      "1   2    Christof Koch            Consciousness   \n",
      "2   3    Steven Pinker  AI in the Age of Reason   \n",
      "3   4    Yoshua Bengio            Deep Learning   \n",
      "4   5  Vladimir Vapnik     Statistical Learning   \n",
      "\n",
      "                                                text  \n",
      "0  As part of MIT course 6S099, Artificial Genera...  \n",
      "1  As part of MIT course 6S099 on artificial gene...  \n",
      "2  You've studied the human mind, cognition, lang...  \n",
      "3  What difference between biological neural netw...  \n",
      "4  The following is a conversation with Vladimir ...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/podcastdata_dataset.csv')\n",
    "print(df.head())\n",
    "corpus = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f8e10",
   "metadata": {},
   "source": [
    "### Step 3: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87849c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convertir el texto a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar signos de puntuación\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Eliminar stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d10b7e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  As part of MIT course 6S099, Artificial Genera...   \n",
      "1  As part of MIT course 6S099 on artificial gene...   \n",
      "2  You've studied the human mind, cognition, lang...   \n",
      "3  What difference between biological neural netw...   \n",
      "4  The following is a conversation with Vladimir ...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  part mit course 6s099 artificial general intel...  \n",
      "1  part mit course 6s099 artificial general intel...  \n",
      "2  youve studied human mind cognition language vi...  \n",
      "3  difference biological neural networks artifici...  \n",
      "4  following conversation vladimir vapnik hes co ...  \n"
     ]
    }
   ],
   "source": [
    "# Aplica la función clean_text a la columna 'text' y guarda el resultado en una nueva columna 'cleaned_text'\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "print(df[['text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0939846d",
   "metadata": {},
   "source": [
    "###  Step 4: Vector Space Representation - TF-IDF\n",
    "\n",
    "Create TF-IDF vector representations of the transcripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2c621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(df['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d4ffa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 49728)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a5e2ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte la matriz TF-IDF a un DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf_vectors.toarray(), columns=tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76eb505",
   "metadata": {},
   "source": [
    "### Step 5: Vector Space Representation - BERT\n",
    "\n",
    "Create BERT vector representations of the transcripts using a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea420eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e39d289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define una función para obtener las representaciones de BERT\n",
    "def generate_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "        outputs = bert_model(**inputs)\n",
    "        embeddings.append(outputs.last_hidden_state[:, 0, :].detach().numpy())  # Use [CLS] token representation\n",
    "    return np.array(embeddings).transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4a6d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera las representaciones de BERT para el corpus de textos limpios\n",
    "cleaned_corpus = df['cleaned_text'].tolist()\n",
    "corpus_bert_embeddings = generate_bert_embeddings(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc2aab8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 768, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_bert_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225b220",
   "metadata": {},
   "source": [
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dad010a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la función de recuperación usando TF-IDF\n",
    "def retrieve_tfidf(query):\n",
    "    # Asegúrate de que la consulta sea una cadena de texto\n",
    "    if isinstance(query, list):\n",
    "        query = ' '.join(query)\n",
    "    \n",
    "    query = clean_text(query)\n",
    "    query_vector = tfidf_vectorizer.transform([query])\n",
    "    similitudes = cosine_similarity(tfidf_vectors, query_vector)\n",
    "    similitudes_df = pd.DataFrame(similitudes, columns=['sims_tfidf'])\n",
    "    similitudes_df['ep'] = df['title']\n",
    "    return similitudes_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "423707ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sims_tfidf                                                 ep\n",
      "0      0.041250                                           Life 3.0\n",
      "1      0.065067                                      Consciousness\n",
      "2      0.000000                            AI in the Age of Reason\n",
      "3      0.000000                                      Deep Learning\n",
      "4      0.010650                               Statistical Learning\n",
      "..          ...                                                ...\n",
      "314    0.037059    Singularity, Superintelligence, and Immortality\n",
      "315    0.013135   Emotion AI, Social Robots, and Self-Driving Cars\n",
      "316    0.001287  Comedy, MADtv, AI, Friendship, Madness, and Pr...\n",
      "317    0.004625                                              Poker\n",
      "318    0.013164  Biology, Life, Aliens, Evolution, Embryogenesi...\n",
      "\n",
      "[319 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"Computer\"\n",
    "result = retrieve_tfidf(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5732e3",
   "metadata": {},
   "source": [
    "### Step 6: Query Processing\n",
    "\n",
    "Define a function to process the query and compute similarity scores using both BERT embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a934919d95ac2de",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Step 7: Retrieve and Compare Results\n",
    "\n",
    "Define a function to retrieve the top results based on similarity scores for both TF-IDF and BERT representations.\n",
    "\n",
    "### Step 8: Test the IR System\n",
    "\n",
    "Test the system with a sample query.\n",
    "\n",
    "Retrieve and display the top results using both TF-IDF and BERT representations.\n",
    "\n",
    "### Step 9: Compare Results\n",
    "\n",
    "Analyze and compare the results obtained from TF-IDF and BERT representations.\n",
    "\n",
    "Discuss the differences, strengths, and weaknesses of each method based on the retrieval results.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "* Follow the steps outlined above to implement the IR system.\n",
    "* Run the provided code snippets to understand how each part of the system works.\n",
    "* Test the system with various queries to observe the results from both TF-IDF and BERT representations.\n",
    "* Compare and analyze the results. Discuss the pros and cons of each method.\n",
    "* Document your findings and any improvements you make to the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import kaggle\n",
    "import pandas as pd\n",
    "wine_df = pd.read_csv('data/podcastdata_dataset.csv')\n",
    "print(wine_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23271bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Descargar recursos de nltk necesarios\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f0ec67",
   "metadata": {},
   "source": [
    "# Preporcesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3de2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_procesado = []\n",
    "for doc in corpus[:10]:\n",
    "    #print (len(doc.split()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b0638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuación\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenizar\n",
    "    words = word_tokenize(text)\n",
    "    # Eliminar palabras vacías\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lematizar\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Unir palabras procesadas en una sola cadena\n",
    "    processed_text = ' '.join(words)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f9fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df['processed_text'] = wine_df['text'].apply(preprocess_text)\n",
    "\n",
    "# Mostrar el DataFrame con la nueva columna de texto procesado\n",
    "print(wine_df[['id', 'guest', 'title', 'processed_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e423569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f66c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un objeto TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustar y transformar los datos de texto\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(wine_df['processed_text'])\n",
    "\n",
    "# Obtener las características (vocabulario)\n",
    "features = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convertir la matriz TF-IDF a un DataFrame pandas (opcional)\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=features)\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame TF-IDF\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Cargar el modelo preentrenado BERT y el tokenizador\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Función para obtener la representación de BERT\n",
    "def get_bert_embedding(text):\n",
    "    # Tokenizar el texto y convertirlo en IDs de tokens\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    \n",
    "    # Obtener las salidas ocultas del modelo BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state  # Última capa oculta como representación\n",
    "    \n",
    "    # Promediar las representaciones de todos los tokens\n",
    "    avg_embeddings = torch.mean(embeddings, dim=1).squeeze()  # Promedio sobre la dimensión de tokens\n",
    "    \n",
    "    return avg_embeddings.numpy()  # Convertir a numpy array para trabajar con pandas\n",
    "\n",
    "# Aplicar la función a tu DataFrame\n",
    "wine_df['bert_embedding'] = wine_df['text'].apply(get_bert_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d993324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
